# 強化学習 Reversi

## agent.py
### Usage:  
  + python agent.py [--gpu &lt;gpu id&gt;] [--size &lt;board size&gt;]  
    --gpu : GPU ID  
    --size : オセロのボードサイズ、既定値6。  
**ボードサイズは environment.py を起動時の指定と一致しなければならない。**

### Description:  
DQN を用いて教科学習を行うエージェントです。  
rl_glue を通して、environment.py から以下の内容を受け取り、DQN により最良の手を判断、実行し、rl_glue に返します。

|層|内容|
|:-|:-|
|0 |自分のコマの位置(Agent) |
|1 |相手のコマの位置(Environment)
|2 |自分がコマを置ける位置
|3 |相手がコマを置ける位置|

層 2 に置ける場所が示されている限り、エージェントは コマを置き続けます。
もし、層 2 自分のコマを置ける場所がない場合、エージェントはパスします。

例)6x6 盤 で以下のような状態の場合:  

|-|0|1|2|3|4|5|
|:-|:-|:-|:-|:-|:-|:-|
|0|0|0|0|0|0|0|
|1|0|0|0|0|0|0|
|2|0|1|-1|0|0|0|
|3|0|1|1|0|0|0|
|4|0|1|0|0|0|0|
|5|0|0|0|0|0|0|

入力内容は以下  
#### 0層
|-|0|1|2|3|4|5|
|:-|:-|:-|:-|:-|:-|:-|
|0|0|0|0|0|0|0|
|1|0|0|0|0|0|0|
|2|0|1|0|0|0|0|
|3|0|1|1|0|0|0|
|4|0|1|0|0|0|0|
|5|0|0|0|0|0|0|

#### 1層
|-|0|1|2|3|4|5|
|:-|:-|:-|:-|:-|:-|:-|
|0|0|0|0|0|0|0|
|1|0|0|0|0|0|0|
|2|0|0|1|0|0|0|
|3|0|0|0|0|0|0|
|4|0|0|0|0|0|0|
|5|0|0|0|0|0|0|

#### 2層
|-|0|1|2|3|4|5|
|:-|:-|:-|:-|:-|:-|:-|
|0|0|0|0|0|0|0|
|1|0|0|1|1|0|0|
|2|0|0|0|1|0|0|
|3|0|0|0|0|0|0|
|4|0|0|0|0|0|0|
|5|0|0|0|0|0|0|

#### 3層
|-|0|1|2|3|4|5|
|:-|:-|:-|:-|:-|:-|:-|
|0|0|0|0|0|0|0|
|1|0|0|0|0|0|0|
|2|1|0|0|0|0|0|
|3|0|0|0|0|0|0|
|4|1|0|1|0|0|0|
|5|0|0|0|0|0|0|

DNN について、入力層は、environment.py から取得した上述の4つの情報を元に作成します。
隠れ層は全結合 8 層のネットワークとしています。  
出力層はボードサイズと一致する数のノード数を持ちます。  

例) ボードサイズが　8x8 の場合、ネットワークは、以下となります。  
    +
    入力層(8 x 8 x 4=256)  
    <ReLU>  
    隠れ層0(8 x 8 x 4=256)  
    <ReLU>  
    隠れ層1(8 x 8 x 4=256)  
    :  
    :  
    <ReLU>  
    隠れ層7(8 x 8 x 4=256)  
    <ReLU>  
    出力層(8x8=64)

この他の動作は、書籍「実装 ディープラーニング」に従います。

## environment.py
### Usage:  
  + python environment.py [--size &lt;board size&gt;]  
  --size : オセロのボードサイズ、既定値6。  
**ボードサイズは agent.py を起動時の指定と一致しなければならない。**  

### Description:  
(後日記述)  

## Game_Reversi.py
### Usage:  
  + (なし。environment.py から参照される。)  

### Description:  
(後日記述)  

## experiment.py
### Usage:  
  + python environment.py [--size &lt;board size&gt;]  

### Description:  
(後日記述)  
